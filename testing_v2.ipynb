{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUesW0hsGPKDTYxR1W+A56",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monaja/reinforcement_learning/blob/main/testing_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwb48pkiKwNb",
        "outputId": "9a039b90-431f-461a-bc5f-8f2755aa869c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello World!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"I am getting start with coding using the BNN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjxjxadGK252",
        "outputId": "d068377d-116d-4d26-93aa-5f723d49cda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am getting start with coding using the BNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class BNNLayer:\n",
        "    \"\"\"\n",
        "    A class representing a layer in a Bayesian Neural Network (BNN).\n",
        "\n",
        "    Attributes:\n",
        "        input_dim (int): The dimension of the input to the layer.\n",
        "        output_dim (int): The dimension of the output of the layer.\n",
        "        weights_mean (np.ndarray): The mean of the weight distribution.\n",
        "        weights_std (np.ndarray): The standard deviation of the weight distribution.\n",
        "        bias_mean (np.ndarray): The mean of the bias distribution.\n",
        "        bias_std (np.ndarray): The standard deviation of the bias distribution.\n",
        "        activation (str): The activation function to use ('relu', 'sigmoid', or 'linear').\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, activation='relu'):\n",
        "        \"\"\"\n",
        "        Initializes the BNNLayer with random weights and biases.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): The dimension of the input to the layer.\n",
        "            output_dim (int): The dimension of the output of the layer.\n",
        "            activation (str): The activation function to use ('relu', 'sigmoid', or 'linear').\n",
        "        \"\"\"\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.activation = activation\n",
        "\n",
        "        # Initialize weights and biases with random values\n",
        "        self.weights_mean = np.random.randn(input_dim, output_dim) * 0.1\n",
        "        self.weights_std = np.ones((input_dim, output_dim)) * 0.1\n",
        "        self.bias_mean = np.zeros((1, output_dim))\n",
        "        self.bias_std = np.ones((1, output_dim)) * 0.1\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Performs a forward pass through the layer, sampling weights and biases.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): The input to the layer.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: The output of the layer.\n",
        "        \"\"\"\n",
        "\n",
        "        # Sample weights and biases from their distributions\n",
        "        weights = np.random.normal(self.weights_mean, self.weights_std)\n",
        "        bias = np.random.normal(self.bias_mean, self.bias_std)\n",
        "\n",
        "        # Calculate the output\n",
        "        z = np.dot(x, weights) + bias\n",
        "\n",
        "        # Apply the activation function\n",
        "        if self.activation == 'relu':\n",
        "            return np.maximum(0, z)\n",
        "        elif self.activation == 'sigmoid':\n",
        "            return 1 / (1 + np.exp(-z))\n",
        "        else:  # 'linear'\n",
        "            return z\n",
        "\n",
        "class BNN:\n",
        "    \"\"\"\n",
        "    A class representing a Bayesian Neural Network (BNN).\n",
        "\n",
        "    Attributes:\n",
        "        layers (list): A list of BNNLayer objects.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer_sizes, activation='relu'):\n",
        "        \"\"\"\n",
        "        Initializes the BNN with a given architecture.\n",
        "\n",
        "        Args:\n",
        "            layer_sizes (list): A list of integers specifying the number of units in each layer.\n",
        "            activation (str): The activation function to use in all layers ('relu', 'sigmoid', or 'linear').\n",
        "        \"\"\"\n",
        "\n",
        "        self.layers = []\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            self.layers.append(BNNLayer(layer_sizes[i], layer_sizes[i + 1], activation))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Performs a forward pass through the entire network, sampling weights and biases in each layer.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): The input to the network.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: The output of the network.\n",
        "        \"\"\"\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    def predict(self, x, num_samples=10):\n",
        "        \"\"\"\n",
        "        Predicts the output for a given input by averaging predictions from multiple forward passes.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): The input to the network.\n",
        "            num_samples (int): The number of forward passes to perform.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: The predicted output, averaged over multiple samples.\n",
        "        \"\"\"\n",
        "\n",
        "        predictions = []\n",
        "        for _ in range(num_samples):\n",
        "            predictions.append(self.forward(x))\n",
        "        return np.mean(predictions, axis=0)\n",
        "\n",
        "# Example usage:\n",
        "# Define the network architecture\n",
        "layer_sizes = [2, 10, 1]  # Input size 2, hidden layer size 10, output size 1\n",
        "\n",
        "# Create the BNN\n",
        "bnn = BNN(layer_sizes)\n",
        "\n",
        "# Generate some random input data\n",
        "input_data = np.random.randn(100, 2)\n",
        "\n",
        "# Make predictions\n",
        "predictions = bnn.predict(input_data)\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "mmtd6Q1hK9mc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea1c8ba-6fda-44d0-a493-7bf65d54e177"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.02121098]\n",
            " [0.04009214]\n",
            " [0.04279467]\n",
            " [0.01777401]\n",
            " [0.01904652]\n",
            " [0.00981167]\n",
            " [0.01820589]\n",
            " [0.02932795]\n",
            " [0.01138345]\n",
            " [0.01925788]\n",
            " [0.01133909]\n",
            " [0.01740155]\n",
            " [0.01022606]\n",
            " [0.0133162 ]\n",
            " [0.01426076]\n",
            " [0.04198015]\n",
            " [0.02101882]\n",
            " [0.01733925]\n",
            " [0.01109839]\n",
            " [0.01068401]\n",
            " [0.01065888]\n",
            " [0.01634881]\n",
            " [0.04723715]\n",
            " [0.04371405]\n",
            " [0.01928733]\n",
            " [0.02037355]\n",
            " [0.01240067]\n",
            " [0.02076232]\n",
            " [0.02414243]\n",
            " [0.01986264]\n",
            " [0.02467897]\n",
            " [0.01666974]\n",
            " [0.02086217]\n",
            " [0.03300502]\n",
            " [0.01607181]\n",
            " [0.02517635]\n",
            " [0.01817962]\n",
            " [0.02069767]\n",
            " [0.01673382]\n",
            " [0.03512994]\n",
            " [0.02639485]\n",
            " [0.02079174]\n",
            " [0.01952651]\n",
            " [0.01513108]\n",
            " [0.01872493]\n",
            " [0.04054034]\n",
            " [0.01867282]\n",
            " [0.01558223]\n",
            " [0.02543102]\n",
            " [0.01099515]\n",
            " [0.02018958]\n",
            " [0.01306291]\n",
            " [0.01951267]\n",
            " [0.01720059]\n",
            " [0.02955256]\n",
            " [0.01573097]\n",
            " [0.05858292]\n",
            " [0.02255985]\n",
            " [0.01826847]\n",
            " [0.0193589 ]\n",
            " [0.02567932]\n",
            " [0.02330708]\n",
            " [0.01734923]\n",
            " [0.02073562]\n",
            " [0.01722386]\n",
            " [0.01772718]\n",
            " [0.0356244 ]\n",
            " [0.01227033]\n",
            " [0.01851418]\n",
            " [0.02086516]\n",
            " [0.01351019]\n",
            " [0.01952876]\n",
            " [0.03301053]\n",
            " [0.01177434]\n",
            " [0.01310685]\n",
            " [0.01301414]\n",
            " [0.01840234]\n",
            " [0.01413895]\n",
            " [0.03237188]\n",
            " [0.03833361]\n",
            " [0.02143688]\n",
            " [0.03769448]\n",
            " [0.01208956]\n",
            " [0.01879093]\n",
            " [0.02782864]\n",
            " [0.01347082]\n",
            " [0.02684037]\n",
            " [0.01008702]\n",
            " [0.01475207]\n",
            " [0.03702679]\n",
            " [0.01595182]\n",
            " [0.02024368]\n",
            " [0.03364892]\n",
            " [0.01114009]\n",
            " [0.02544524]\n",
            " [0.02059524]\n",
            " [0.04894719]\n",
            " [0.04977269]\n",
            " [0.02473976]\n",
            " [0.01182335]]\n"
          ]
        }
      ]
    }
  ]
}